package org.firstinspires.ftc.teamcode.AutoTests.LastYearsAutos;

import static com.qualcomm.robotcore.hardware.DcMotor.ZeroPowerBehavior.BRAKE;

import com.acmerobotics.dashboard.FtcDashboard;
import com.acmerobotics.dashboard.telemetry.MultipleTelemetry;
import com.acmerobotics.roadrunner.geometry.Pose2d;
import com.acmerobotics.roadrunner.geometry.Vector2d;
import com.acmerobotics.roadrunner.trajectory.Trajectory;
import com.qualcomm.hardware.bosch.BNO055IMU;
import com.qualcomm.robotcore.eventloop.opmode.Autonomous;
import com.qualcomm.robotcore.eventloop.opmode.Disabled;
import com.qualcomm.robotcore.eventloop.opmode.LinearOpMode;
import com.qualcomm.robotcore.hardware.DcMotor;
import com.qualcomm.robotcore.hardware.Servo;
import org.firstinspires.ftc.robotcore.external.hardware.camera.WebcamName;
import org.firstinspires.ftc.robotcore.external.navigation.AngleUnit;
import org.firstinspires.ftc.robotcore.external.navigation.AxesOrder;
import org.firstinspires.ftc.robotcore.external.navigation.AxesReference;
import org.firstinspires.ftc.robotcore.external.navigation.Orientation;
import org.firstinspires.ftc.teamcode.drive.SampleMecanumDrive;
import org.opencv.core.Core;
import org.opencv.core.Mat;
import org.opencv.core.MatOfPoint;
import org.opencv.core.Point;
import org.opencv.core.Rect;
import org.opencv.core.Scalar;
import org.opencv.core.Size;
import org.opencv.imgproc.Imgproc;
import org.opencv.imgproc.Moments;
import org.openftc.apriltag.AprilTagDetection;
import org.openftc.easyopencv.OpenCvCamera;
import org.openftc.easyopencv.OpenCvCameraFactory;
import org.openftc.easyopencv.OpenCvCameraRotation;
import org.openftc.easyopencv.OpenCvPipeline;
import java.util.ArrayList;
import java.util.List;

// correctly detects both pipelines
@Disabled
@Autonomous(name = "Zohra's Far Red Auto")
public class FarRedAuto extends LinearOpMode {
    private static final int CAMERA_WIDTH = 640; // width  of wanted camera resolution
    private static final int CAMERA_HEIGHT = 360; // height of wanted camera resolution
    private static final double FOV = 40;

    private double strafeApril;

    OpenCvCamera controlHubCam;
    OpenCvCamera aprilTagCam;
    AprilTagDetectionPipeline aprilTagDetectionPipeline;

    static final double FEET_PER_METER = 3.28084;

    // Lens intrinsics
    // UNITS ARE PIXELS
    // NOTE: this calibration is for the C270 webcam at 640x360
    double fx = 822.317;
    double fy = 822.317;
    double cx = 319.495;
    double cy = 242.502;
    int side = 0;

    // UNITS ARE METERS
    double tagsize = 0.166;

    // RED ALLIANCE TAGS
    int ID_TAG_OF_INTEREST_LEFT = 4;
    int ID_TAG_OF_INTEREST_MID = 5;
    int ID_TAG_OF_INTEREST_RIGHT = 6;

    private BNO055IMU imu;
    private double cX = 0;
    private double cY = 0;
    private double width = 0;

    // Calculate the distance using the formula
    public static final double objectWidthInRealWorldUnits = 3.75;  // Replace with the actual width of the object in real-world units
    public static final double focalLength = 416;  // Replace with the focal length of the camera in pixels

    @Override
    public void runOpMode() {
        SampleMecanumDrive drive = new SampleMecanumDrive(hardwareMap);
        DcMotor motorLinearSlides1 = hardwareMap.dcMotor.get("motorLinearSlides1");
        DcMotor motorLinearSlides2 = hardwareMap.dcMotor.get("motorLinearSlides2");

        DcMotor activeIntake = hardwareMap.dcMotor.get("activeIntake");

        Servo twisty = hardwareMap.servo.get("twisty");
        twisty.setDirection(Servo.Direction.FORWARD);

        motorLinearSlides1.setZeroPowerBehavior(BRAKE);
        motorLinearSlides2.setZeroPowerBehavior(BRAKE);

        activeIntake.setMode(DcMotor.RunMode.RUN_WITHOUT_ENCODER);
        activeIntake.setZeroPowerBehavior(BRAKE);

        Servo leftPickup = hardwareMap.servo.get("leftPickup");
        Servo rightPickup = hardwareMap.servo.get("rightPickup");

        leftPickup.setDirection(Servo.Direction.FORWARD);
        rightPickup.setDirection(Servo.Direction.FORWARD);

        Servo wristServo = hardwareMap.servo.get("wristServo");
        wristServo.setDirection(Servo.Direction.FORWARD);

        // finally the arm thingy
        Servo armServoRight = hardwareMap.servo.get("armServoRight");
        Servo armServoLeft = hardwareMap.servo.get("armServoLeft");

        // one of these will have to be reversed
        armServoRight.setDirection(Servo.Direction.FORWARD);
        armServoLeft.setDirection(Servo.Direction.FORWARD);

        // for initializing cameras
        int cameraMonitorViewId = hardwareMap.appContext.getResources().getIdentifier("cameraMonitorViewId", "id", hardwareMap.appContext.getPackageName());
        int[] viewportContainerIds = OpenCvCameraFactory.getInstance()
                .splitLayoutForMultipleViewports(
                        cameraMonitorViewId, //The container we're splitting
                        2, //The number of sub-containers to create
                        OpenCvCameraFactory.ViewportSplitMethod.VERTICALLY); //Whether to split the container vertically or horizontally

        // initialize cameras and detection pipeline
        controlHubCam = OpenCvCameraFactory.getInstance().createWebcam(hardwareMap.get(WebcamName.class, "Webcam 1"), viewportContainerIds[0]);
        aprilTagCam = OpenCvCameraFactory.getInstance().createWebcam(hardwareMap.get(WebcamName.class, "Webcam 2"), viewportContainerIds[1]);
        aprilTagDetectionPipeline = new AprilTagDetectionPipeline(tagsize, fx, fy, cx, cy);

        // open cameras safely
        controlHubCam.openCameraDeviceAsync(new OpenCvCamera.AsyncCameraOpenListener() {
            @Override
            public void onOpened() {
                controlHubCam.setPipeline(new RedBlobDetectionPipeline(false));
                controlHubCam.startStreaming(320, 240, OpenCvCameraRotation.UPRIGHT);
            }

            @Override
            public void onError(int errorCode) {
                telemetry.addData("Control hub cam:", "failed");
            }
        });
        controlHubCam.pauseViewport();  // save cpu power
        aprilTagCam.openCameraDeviceAsync(new OpenCvCamera.AsyncCameraOpenListener() {
            @Override
            public void onOpened() {
                aprilTagCam.setPipeline(aprilTagDetectionPipeline);
                aprilTagCam.startStreaming(320, 240, OpenCvCameraRotation.UPRIGHT);
            }

            @Override
            public void onError(int errorCode) {
                telemetry.addData("April tag cam:", "failed");
            }
        });

        FtcDashboard dashboard = FtcDashboard.getInstance();
        dashboard.startCameraStream(controlHubCam, 30);
        telemetry = new MultipleTelemetry(telemetry, dashboard.getTelemetry());

        // We want to start the bot at x: -36, y: -62, heading: 90 degrees
        Pose2d startPose = new Pose2d(-36, -62, Math.toRadians(90));

        // sync localizer with motion profiler's location
        drive.setPoseEstimate(startPose);

        // detect team prop
        while(!isStarted() && !isStopRequested()) {
            if (getAngleTarget(cX) < 6.6) {
                side = 3;
                telemetry.addLine("right side!");
            } else if (getAngleTarget(cX) > 6.6 && getAngleTarget(cX) < 14.8) {
                side = 2;
                telemetry.addLine("middle!");
            } else if (getAngleTarget(cX) > 14.8) {
                side = 1;
                telemetry.addLine("left side!");
            } else {
                telemetry.addLine("we're fuckkkkkkkkkkkked");
            }
            telemetry.addData("Side:", side);
            telemetry.addData("pose estimate:", drive.getPoseEstimate());
            telemetry.update();
            sleep(20);
        }

        while(opModeIsActive() && !isStopRequested()) {
            if (side == 1) {  // left side
                Trajectory traj1 = drive.trajectoryBuilder(startPose)
                        .lineToConstantHeading(new Vector2d(-43, -40))
                        .build();
                drive.followTrajectory(traj1);
                sleep(5000);
                requestOpModeStop();
            } else if (side == 2) {  // middle side
                Trajectory traj1 = drive.trajectoryBuilder(startPose)
                        .forward(31)
                        .build();
                drive.followTrajectory(traj1);
                sleep(5000);
                requestOpModeStop();
            } else if (side == 3) {  // right side
                Trajectory traj1 = drive.trajectoryBuilder(startPose)
                        .splineTo(new Vector2d(-34, -43), Math.toRadians(45))
                        .build();
                drive.followTrajectory(traj1);
                sleep(5000);
                requestOpModeStop();
            }
//            switch (side) {
//                case 1:  // left side
//                    Trajectory traj1 = drive.trajectoryBuilder(startPose)
//                            .lineToConstantHeading(new Vector2d(-42, -31))
//                            .build();
//                    drive.followTrajectory(traj1);
//                    sleep(5000);
//                    requestOpModeStop();
//                    break;
//                case 2:  // middle
//                    Trajectory traj1 = drive.trajectoryBuilder(startPose)
//                            .forward(31)
//                            .build();
//                    drive.followTrajectory(traj1);
//                    sleep(5000);
//                    requestOpModeStop();
//                    break;
//                case 3:  // right side
//                    break;
//                default:
//                    break;
//            }
        }
    }

    class RedBlobDetectionPipeline extends OpenCvPipeline {
        boolean isDetectingWhite;
        Scalar lower = new Scalar(0, 0, 0);
        Scalar upper = new Scalar(0, 0, 0);

        RedBlobDetectionPipeline(boolean isDetectingWhite_) {
            isDetectingWhite = isDetectingWhite_;
        }

        @Override
        public Mat processFrame(Mat input) {
            // Preprocess the frame to detect red/white regions
            Mat redMask = preprocessFrame(input);

            // Find contours of the detected red/white regions
            List<MatOfPoint> contours = new ArrayList<>();
            Mat hierarchy = new Mat();
            Imgproc.findContours(redMask, contours, hierarchy, Imgproc.RETR_EXTERNAL, Imgproc.CHAIN_APPROX_SIMPLE);

            // Find the largest red/white contour (blob)
            MatOfPoint largestContour = findLargestContour(contours);

            if (largestContour != null) {
                telemetry.addData("cX: ", cX);

                // Draw a red outline around the largest detected object
                Imgproc.drawContours(input, contours, contours.indexOf(largestContour), new Scalar(255, 0, 0), 2);
                // Calculate the width of the bounding box
                width = calculateWidth(largestContour);

                // Display the width next to the label
                String widthLabel = "Width: " + (int) width + " pixels";
                Imgproc.putText(input, widthLabel, new Point(cX + 10, cY + 20), Imgproc.FONT_HERSHEY_SIMPLEX, 0.5, new Scalar(0, 255, 0), 2);
                //Display the Distance
                String distanceLabel = "Distance: " + String.format("%.2f", getDistance(width)) + " inches";
                Imgproc.putText(input, distanceLabel, new Point(cX + 10, cY + 60), Imgproc.FONT_HERSHEY_SIMPLEX, 0.5, new Scalar(0, 255, 0), 2);
                // Calculate the centroid of the largest contour
                Moments moments = Imgproc.moments(largestContour);
                cX = moments.get_m10() / moments.get_m00();
                cY = moments.get_m01() / moments.get_m00();

                // Draw a dot at the centroid
                String label = "(" + (int) cX + ", " + (int) cY + ")";
                Imgproc.putText(input, label, new Point(cX + 10, cY), Imgproc.FONT_HERSHEY_COMPLEX, 0.5, new Scalar(0, 255, 0), 2);
                Imgproc.circle(input, new Point(cX, cY), 5, new Scalar(0, 255, 0), -1);
            }
            return input;
        }

        private Mat preprocessFrame(Mat frame) {
            Mat hsvFrame = new Mat();
            Imgproc.cvtColor(frame, hsvFrame, Imgproc.COLOR_BGR2HSV);

            // HSV for detecting red colour
            if (isDetectingWhite) {
                lower = new Scalar(0, 0, 200);
                upper = new Scalar(180, 10, 255);
            } else {  // HSV for detecting white pixel
                lower = new Scalar(100, 100, 100);
                upper = new Scalar(180, 255, 255);
            }

            Mat redMask = new Mat();
            Core.inRange(hsvFrame, lower, upper, redMask);
            hsvFrame.release();

            Mat kernel = Imgproc.getStructuringElement(Imgproc.MORPH_RECT, new Size(5, 5));
            Imgproc.morphologyEx(redMask, redMask, Imgproc.MORPH_OPEN, kernel);  // remove noise
            Imgproc.morphologyEx(redMask, redMask, Imgproc.MORPH_CLOSE, kernel);  // add in pixels
            kernel.release();

            return redMask;
        }

        private MatOfPoint findLargestContour(List<MatOfPoint> contours) {
            double maxArea = 0;
            MatOfPoint largestContour = null;

            for (MatOfPoint contour : contours) {
                double area = Imgproc.contourArea(contour);
                if (area > maxArea) {
                    maxArea = area;
                    largestContour = contour;
                }
            }
            return largestContour;
        }

        private double calculateWidth(MatOfPoint contour) {
            Rect boundingRect = Imgproc.boundingRect(contour);
            return boundingRect.width;
        }
    }

    private static double getAngleTarget(double objMidpoint) {
        return -((objMidpoint - (CAMERA_WIDTH/2.0))*FOV)/CAMERA_WIDTH;
    }

    private static double getDistance(double width) {
        return (objectWidthInRealWorldUnits * focalLength) / width;
    }
}